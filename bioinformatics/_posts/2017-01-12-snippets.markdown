---
layout: post
title:  "Bioinformatics snippets"
author: Will Rowe
permalink: /bioinformatics-snippets/
---

This page covers some useful code snippets that I regularly use, as well as listing good resources for learning more about UNIX.

***

* TOC
{:toc}

***

## UNIX

Useful UNIX cheatsheets can be found [here][cheats-1] and [here][cheats-2].


### 1. Find / Grep / Awk

```bash
# recursively find files with an extension, then print file list to file (use abs. path in find term to get abs. path in output)
find ./ -type f -name "*.bam" -printf "%f\n" > all_bam_files.txt

# recursively find files with an extension, then print files + relative paths to file
find ./ -type f -name "*.bam" -print > all_bam_files.txt

# find files by name and then grep for string
find ./ -type f -name krakenreport -exec grep "Streptococcus pneumoniae" {} \+

# average file size in directory (recursively searches for files greater than 1 GB)
find ./0001_RNA_SEQ/ -size +1G -ls | awk '{sum += $7; n++;} END {print sum/n;}'

# find and move files
find ../ -type f -name '*.all.txt' -exec mv -t ./ {} \+

# multifasta to single fasta entry (for ACT etc.)
grep -v "^>" multifasta.fasta | awk 'BEGIN { ORS=""; print ">Sequence_name\n" } { print }' > merged.fasta

# extract subset from fasta file (using headers.txt file)
awk 'BEGIN{while((getline<"headers.txt")>0)l[">"$1]=1}/^>/{f=l[$1]?1:0}f' input.fasta > subset.fasta

# remove duplicates in file
awk '!seen[$0]++' filename

# append read pair info to a fastq file
gunzip -c SRR2352233_pass_1.fastq.gz |  awk '{if(NR%4==1) $0=sprintf("%s_1",($0)); print;}' | gzip -c > SRR2352233_pass_1.r1.fastq.gz
```


### 2. Loops

```bash
# loop over paired fastq files and run a command (e.g. SNIPPY)
for i in ./seqdata/files*_1.fastq.gz
> do
> base=${i%_*.gz}
> dirname=${base##*/}
> snippy --cpus 24 --outdir ./mysnips_$dirname --ref RefSeq.gbf --R1 ${base}_1.fastq.gz --R2 ${base}_2.fastq.gz --unmapped
> done

# Side note: to build tree using core SNPs from above:
snippy-core --prefix core mysnps*
FastTree -gtr -nt core.aln > tree

# Side note: use parallel to run Snippy:
ls ../00_RAW_DATA/ERR-files/*.gz | parallel -j 20% "snippy --cpus 4 --outdir ./snippy/{/.}-results --ref ../01_REFS/D23580.chromosome.fasta --se {}"

# binning multiple flow cell runs into individual sample directories
for i in $(seq -f "%02g" 1 21)
> do
> mkdir sample-$i
> mv flowcell_sample_no_$i.qual.gz ./sample-$i
> mv flowcell_sample_no_$i.csfasta.gz ./sample-$i
> done
```


### 3. Curl / Wget

```bash
# download all files of certain extension from an html page
wget --accept fastq.gz --mirror --convert-links --no-parent http://website.com/dir/subdir/
```


### 4. CGR Cluster

```bash
# password-less SSH login (note --- may need to install `ssh-copy-id` on OSX)
ssh-keygen -t rsa
ssh-copy-id -i /Users/user/.ssh/id_rsa.pub user@server.ac.uk

# use reptyr to attach a running process to a new terminal (i.e. if you forget to screen, start a new screen and migrate running job)
reptyr <PID>

# send an email with an attachment
echo "Have some coverage plots" | mutt -a "./coverage-plots.png" -s "coverage-plots" -- user@liverpool.ac.uk

# send STDOUT and STDERR to file
$CMD >> $filename 2>&1

# use screen to run jobs independent of shell session
#screen  (starts screen session)
#<ctrl+a> and then d (detach screen and leave it running)
#screen -ls (lists running screens)
#screen -x (enters recent screen)
#exit (terminates open screen)

# submit multiple jobs from one server node to worker nodes
PARALLEL_HOSTS=server1,server2,server3
ls /dir/subdir/inputfiles*.gz | parallel --progress --workdir $PWD -j 2% --delay 2.0 -S $PARALLEL_HOSTS \"/dir/bin/program.py -i {} -o $PWD/RESULTS >> $PWD/{/.}.LOG\"

# more advanced example of GNU parallel - spreads bowtie jobs over cluster (1 per node), each job has no intermediate files + fewer idle CPUs
PARALLEL_HOSTS=server1,server2,server3
CMD=/usr/local/share/bowtie2-2.2.5/bowtie2 -x ./01_REFERENCE/REFERENCE -1 {//}/*_1_* -2 {//}/*_2_* -U {//}/*_U1_* -U {//}/*_U2_* -p 40 | /pub46/willr/000_HOME/0003_SOFTWARE/bin/samtools view -@ 40 -m 1G -q 10 -bS - | /pub46/willr/000_HOME/0003_SOFTWARE/bin/samtools sort -@ 40 -m 1G -o - | /pub46/willr/000_HOME/0003_SOFTWARE/bin/samtools rmdup - {//}outfile.sorted.bam
ls 00_RAW_DATA/*/*_1_trimmed.fastq.gz | parallel -S $PARALLEL_HOSTS --workdir $PWD -j 1 \"$CMD\"
```


### 5. GIT

You can find a really good GIT guide [here][git_guide] but the following are some of the common and useful commands:

```bash
# create a new repo or clone an existing one
git init
git clone username@host:/path/to/repo

# check, add, commit and push changes
git status
git add <filename>
git add *
git commit -m "commit message required here"
git push origin master

# add single remote or multiple remotes
git remote add origin <server>
git remote set-url origin --push --add <server>

# replacing local changes (by retrieving last HEAD content or by pulling last history from server)
git checkout -- <filename>
git fetch origin

# open git config in editor
git config -e
```

For information on branching, merging and tagging - read [THIS][git_guide] guide!


### 6. Not sorted yet

```bash
# archive and compress directory using tar and pigz
tar -cf - ../0002_GENOMES/ | pigz > 03.10.2016_0002_GENOMES.tar.gz

# recursively change permissions on directory
chmod -R u=rwx,g=r,o=r 0003_compressed_archives/

# use vim to delete all lines under selected line (command used in vim)
:+,$d

# use vim to delete everything from current line to top of file
dgg

# use cut to remove a column from a file (using tab as delimiter)
cut -d$'\t' -f1-2,4- annotation.gff > annotation.edit.gff

# find differences between two sorted files
comm -3 acc.sorted down.sorted
```

----

## Bioinformatics

### 1. Read alignment

The main short read aligners used by the group are [Bowtie2][bowtie2] and [SMALT][smalt]. These aligners generate alignments in Sequence Alignment Map (SAM) format and [SAMtools][samtools] is a set of tools to process these files. SAMtools can work with binary SAM files (BAM files) without uncompressing the whole file. A really useful tool for understanding SAM flags (-f / -F) is found [here][picard_sam_flags]. The following code snippets are tested with Samtools v1.3.1 and Bowtie2 v2.2.5

```bash
#Â to quickly align reads using Bowtie2 and get a sorted BAM file use the following snippet (commands are piped to reduce disk I/O)
bowtie2 -x REFERENCE -1 r1.fastq -2 r2.fastq -p 40 | samtools view -bS - | samtools sort - -o outfile.sorted.bam && samtools index outfile.sorted.bam

# use flagstat to get alignment information
samtools flagstat outfile.sorted.bam

# count unmapped reads
samtools view -f4 -c outfile.sorted.bam

# remove unmapped reads from alignment file
samtools view -F 0x04 -b outfile.sorted.bam > outfile.aligned_reads_only.sorted.bam

# remove reads below minimum mapping quality (see [here][heng_blog] for MAPQ blog post)
samtools view -q 20 -b outfile.sorted.bam > outfile.q20.sorted.bam

# extract read pairs from alignment where both mapped, one mapped and one didn't
samtools view -b -F 12 outfile.sorted.bam > both.mapped.bam
samtools view -b -f 4 -F 8 outfile.sorted.bam > not.mapped.but.mate.did.bam
samtools view -b -f 8 -F 4 outfile.sorted.bam > mapped.but.mate.didnt.bam
bedtools bamtofastq -i both.mapped.bam -fq 1.fq -fq2 2.fq

# extract reads that mapped to a particular regions
samtools view -b 90.sorted.bam "D23580_liv_chro:368858-410494" -o pBT1.region.bam
```


### 2. Variant calling

A good guide to variant calling can be found [here][vcf] and [here][vcf2].

```bash
# call variants
samtools mpileup -uf ref.fa aln.bam | bcftools call -mv -Oz > calls.vcf.gz

# assess call set quality using transition:transversion ratio
bcftools filter -i'%QUAL>20' calls.vcf.gz | bcftools stats | grep TSTV

# filter variants (note --- the filtering parameters should be considered for each sample)
bcftools filter -sLowQual -g3 -G10 -e '%QUAL<20' calls.vcf.gz > calls.filtered.vcf
```


### 3. Assembly

### 4. QC

```bash
# use kraken to quickly bin reads according to taxa
kraken --threads 10 --preload --fastq-input --gzip-compressed --db /path/to/DBs/minikraken_20141208 input_file*.fastq.gz | kraken-report --db /path/to/DBs/minikraken_20141208 > ./kraken_output.report
```

### 5. File conversion

```bash
# gff to genbank
seqret -sequence input.fasta -feature --fformat gff -fopenfile input.gff -osformat genbank -auto
```


---


[cheats-1]: http://www.rain.org/~mkummel/unix.html
[cheats-2]: http://cgr.liv.ac.uk/cinfo/guide.html
[git_guide]: http://rogerdudler.github.io/git-guide/
[bowtie2]: http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml
[smalt]: http://www.sanger.ac.uk/science/tools/smalt-0
[samtools]: http://www.htslib.org/doc/samtools.html
[picard_sam_flags]: https://broadinstitute.github.io/picard/explain-flags.html
[heng_blog]: http://lh3lh3.users.sourceforge.net/mapuniq.shtml
[vcf]: https://github.com/samtools/bcftools/wiki/HOWTOs
[vcf2]: https://github.com/ekg/alignment-and-variant-calling-tutorial
